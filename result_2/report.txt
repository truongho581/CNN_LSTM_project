# Tráº¡m Ä‘á»ƒ láº¥y data test
station_data = ["FS10D", 40.4328, -124.6940, -1153.8]  #2014-07-17	2015-08-27

# Tráº¡m Ä‘á»ƒ láº¥y data train/val
#station_data = ["M11B", 42.9320, -125.0171, -1109.0]   #2012-09-02	2013-06-18   58 sá»± kiá»‡n
#station_data = ["M12B", 42.1840, -124.9461, -1045.0]   #2012-09-02	2013-06-18   115 sá»± kiá»‡n
#station_data = ["FS41D", 40.6124, -124.7310, -1079.3]  #2014-07-16	2015-08-28   124 sá»± kiá»‡n
#station_data = ["FS16D", 40.5378, -124.7468, -1080.4]  #2014-07-16	2015-08-28   121 sá»± kiá»‡n

=========================================================================================================================

Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)                    â”ƒ Output Shape           â”ƒ       Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer (InputLayer)        â”‚ (None, 128, 128, 1)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)                 â”‚ (None, 128, 128, 32)   â”‚           320 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization             â”‚ (None, 128, 128, 32)   â”‚           128 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation (Activation)         â”‚ (None, 128, 128, 32)   â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d (MaxPooling2D)    â”‚ (None, 64, 64, 32)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)               â”‚ (None, 64, 64, 32)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)               â”‚ (None, 64, 64, 64)     â”‚        18,496 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_1           â”‚ (None, 64, 64, 64)     â”‚           256 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_1 (Activation)       â”‚ (None, 64, 64, 64)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1 (MaxPooling2D)  â”‚ (None, 32, 32, 64)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1 (Dropout)             â”‚ (None, 32, 32, 64)     â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)               â”‚ (None, 32, 32, 128)    â”‚        73,856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalization_2           â”‚ (None, 32, 32, 128)    â”‚           512 â”‚
â”‚ (BatchNormalization)            â”‚                        â”‚               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_2 (Activation)       â”‚ (None, 32, 32, 128)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2 (MaxPooling2D)  â”‚ (None, 16, 16, 128)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2 (Dropout)             â”‚ (None, 16, 16, 128)    â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ reshape (Reshape)               â”‚ (None, 16, 2048)       â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bidirectional (Bidirectional)   â”‚ (None, 16, 128)        â”‚     1,081,856 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ bidirectional_1 (Bidirectional) â”‚ (None, 64)             â”‚        41,216 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_3 (Dropout)             â”‚ (None, 64)             â”‚             0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)                   â”‚ (None, 1)              â”‚            65 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 1,216,705 (4.64 MB)
 Trainable params: 1,216,257 (4.64 MB)
 Non-trainable params: 448 (1.75 KB)

=============================================================================================================================
Epoch 1/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8700 - loss: 0.3144
Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to best_model_epoch01_valAcc0.5000.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 238s 5s/step - accuracy: 0.8698 - loss: 0.3147 - val_accuracy: 0.5000 - val_loss: 1.4714 - learning_rate: 0.0010
Epoch 2/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8471 - loss: 0.3570
Epoch 2: val_accuracy did not improve from 0.50000
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 224s 4s/step - accuracy: 0.8473 - loss: 0.3567 - val_accuracy: 0.5000 - val_loss: 1.5609 - learning_rate: 0.0010
Epoch 3/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8554 - loss: 0.3300
Epoch 3: val_accuracy did not improve from 0.50000
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 222s 4s/step - accuracy: 0.8555 - loss: 0.3300 - val_accuracy: 0.5000 - val_loss: 1.3040 - learning_rate: 0.0010
Epoch 4/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8700 - loss: 0.3156
Epoch 4: val_accuracy did not improve from 0.50000
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 223s 4s/step - accuracy: 0.8700 - loss: 0.3155 - val_accuracy: 0.5000 - val_loss: 1.6455 - learning_rate: 0.0010
Epoch 5/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8545 - loss: 0.3290
Epoch 5: val_accuracy improved from 0.50000 to 0.58125, saving model to best_model_epoch05_valAcc0.5813.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 228s 5s/step - accuracy: 0.8547 - loss: 0.3289 - val_accuracy: 0.5813 - val_loss: 1.0424 - learning_rate: 0.0010
Epoch 6/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8632 - loss: 0.3262
Epoch 6: val_accuracy improved from 0.58125 to 0.74125, saving model to best_model_epoch06_valAcc0.7412.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 261s 5s/step - accuracy: 0.8631 - loss: 0.3263 - val_accuracy: 0.7412 - val_loss: 0.4901 - learning_rate: 0.0010
Epoch 7/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8644 - loss: 0.3094
Epoch 7: val_accuracy improved from 0.74125 to 0.90250, saving model to best_model_epoch07_valAcc0.9025.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 229s 5s/step - accuracy: 0.8643 - loss: 0.3096 - val_accuracy: 0.9025 - val_loss: 0.2848 - learning_rate: 0.0010
Epoch 8/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8487 - loss: 0.3485
Epoch 8: val_accuracy did not improve from 0.90250
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 226s 5s/step - accuracy: 0.8488 - loss: 0.3483 - val_accuracy: 0.8788 - val_loss: 0.2914 - learning_rate: 0.0010
Epoch 9/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8728 - loss: 0.3069
Epoch 9: val_accuracy improved from 0.90250 to 0.91875, saving model to best_model_epoch09_valAcc0.9187.h5
WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. 
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 228s 5s/step - accuracy: 0.8728 - loss: 0.3069 - val_accuracy: 0.9187 - val_loss: 0.2292 - learning_rate: 0.0010
Epoch 10/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8691 - loss: 0.3229
Epoch 10: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 226s 5s/step - accuracy: 0.8693 - loss: 0.3225 - val_accuracy: 0.5537 - val_loss: 1.1464 - learning_rate: 0.0010
Epoch 11/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8597 - loss: 0.3232
Epoch 11: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 226s 4s/step - accuracy: 0.8600 - loss: 0.3230 - val_accuracy: 0.6600 - val_loss: 0.7855 - learning_rate: 0.0010
Epoch 12/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8644 - loss: 0.3196
Epoch 12: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 270s 5s/step - accuracy: 0.8646 - loss: 0.3193 - val_accuracy: 0.9100 - val_loss: 0.2240 - learning_rate: 0.0010
Epoch 13/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8778 - loss: 0.2906
Epoch 13: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 233s 5s/step - accuracy: 0.8777 - loss: 0.2908 - val_accuracy: 0.9050 - val_loss: 0.2326 - learning_rate: 0.0010
Epoch 14/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8714 - loss: 0.2953
Epoch 14: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 253s 4s/step - accuracy: 0.8716 - loss: 0.2950 - val_accuracy: 0.5000 - val_loss: 1.5434 - learning_rate: 0.0010
Epoch 15/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8897 - loss: 0.2732
Epoch 15: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 222s 4s/step - accuracy: 0.8898 - loss: 0.2731 - val_accuracy: 0.8875 - val_loss: 0.2518 - learning_rate: 0.0010
Epoch 16/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8817 - loss: 0.2995
Epoch 16: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 222s 4s/step - accuracy: 0.8817 - loss: 0.2993 - val_accuracy: 0.5000 - val_loss: 1.5565 - learning_rate: 0.0010
Epoch 17/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8696 - loss: 0.3012
Epoch 17: val_accuracy did not improve from 0.91875

Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 224s 4s/step - accuracy: 0.8698 - loss: 0.3010 - val_accuracy: 0.6762 - val_loss: 0.7251 - learning_rate: 0.0010
Epoch 18/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8955 - loss: 0.2543
Epoch 18: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 224s 4s/step - accuracy: 0.8954 - loss: 0.2546 - val_accuracy: 0.8725 - val_loss: 0.2605 - learning_rate: 5.0000e-04
Epoch 19/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.9007 - loss: 0.2632
Epoch 19: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 233s 5s/step - accuracy: 0.9006 - loss: 0.2632 - val_accuracy: 0.7412 - val_loss: 0.7164 - learning_rate: 5.0000e-04
Epoch 20/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8869 - loss: 0.2656
Epoch 20: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 227s 5s/step - accuracy: 0.8869 - loss: 0.2656 - val_accuracy: 0.8813 - val_loss: 0.2685 - learning_rate: 5.0000e-04
Epoch 21/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.9046 - loss: 0.2434
Epoch 21: val_accuracy did not improve from 0.91875
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 223s 4s/step - accuracy: 0.9045 - loss: 0.2435 - val_accuracy: 0.8737 - val_loss: 0.2759 - learning_rate: 5.0000e-04
Epoch 22/50
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 0s 4s/step - accuracy: 0.8973 - loss: 0.2657
Epoch 22: val_accuracy did not improve from 0.91875

Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
50/50 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 223s 4s/step - accuracy: 0.8973 - loss: 0.2658 - val_accuracy: 0.5000 - val_loss: 2.1471 - learning_rate: 5.0000e-04
Epoch 22: early stopping
Restoring model weights from the end of the best epoch: 12.
======================================================================================================================================================================================

âœ… Best model found: best_model_epoch09_valAcc0.9187.h5
WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.
âœ… Model loaded successfully.
â„¹ï¸ Creating test_data generator...
Found 736 images belonging to 2 classes.
/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.
  self._warn_if_super_not_called()
12/12 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 13s 941ms/step - accuracy: 0.9272 - loss: 0.2096
ğŸ¯ Test Accuracy: 95.11%
12/12 â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12s 864ms/step

ğŸ“Š Classification Report:
              precision    recall  f1-score   support

       Noise       0.97      0.93      0.95       368
  Earthquake       0.93      0.98      0.95       368

    accuracy                           0.95       736
   macro avg       0.95      0.95      0.95       736
weighted avg       0.95      0.95      0.95       736

ğŸ”¬ ROC AUC: 0.9939